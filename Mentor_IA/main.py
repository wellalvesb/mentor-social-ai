import os
import sqlite3
import uvicorn
from fastapi import FastAPI
from pydantic import BaseModel
from groq import Groq
from typing import Optional
import base64

# --- CONFIGURA√á√ÉO GROQ (C√âREBRO E OUVIDOS) ---
# Sua chave Groq (V√°lida para Textos e √Åudios)
# Substitua a linha da chave por isso antes de salvar:
# --- CONFIGURA√á√ÉO ---
# Chave Groq (Llama 3.3 + Whisper V3)
GROQ_API_KEY = os.environ.get("GROQ_API_KEY", "SUA_CHAVE_AQUI")
client = Groq(api_key=GROQ_API_KEY)

# --- PERSONALIDADE (J√öNIOR - O MENTOR DID√ÅTICO E OBJETIVO) ---
# --- PERSONALIDADE (J√öNIOR - O MENTOR CONTA-GOTAS) ---
SYSTEM_PROMPT = """
IDENTIDADE:
Voc√™ √© o 'J√∫nior', um Mentor de Neg√≥cios parceiro e pr√°tico.
Seu p√∫blico tem pressa e baixo letramento digital.

REGRAS DE OURO (ANTI-TEXT√ÉO):
1. **REGRA DO CONTA-GOTAS:** JAMAIS entregue um projeto ou lista gigante de uma vez. Se o assunto for complexo, explique o b√°sico e d√™ APENAS O PRIMEIRO PASSO.
2. **SIMPLIFICA√á√ÉO EXTREMA:** N√£o use termos como "Stakeholders", "Compliance" ou "Infraestrutura" sem explicar. Use met√°foras (ex: "Governan√ßa √© como organizar as prateleiras do estoque").
3. **TAMANHO M√ÅXIMO:** Sua resposta n√£o pode passar de 3 ou 4 par√°grafos curtos. O usu√°rio est√° no celular.

ESTRUTURA DE RESPOSTA OBRIGAT√ìRIA:
1. **Confirma√ß√£o:** "Entendi, Welton!"
2. **Resumo Simples:** Explique o conceito em 1 frase simples.
3. **A√ß√£o Imediata (Passo 1):** Diga a primeira coisa que ele tem que fazer.
4. **Gancho:** Pergunte: "Fez sentido? Podemos ir para o pr√≥ximo passo?"

EXEMPLO DE COMO N√ÉO FAZER (ERRADO):
"Aqui est√° seu plano de Governan√ßa: 1. An√°lise, 2. Pol√≠tica, 3. Implementa√ß√£o..." (ISSO √â CHATO E LONGO).

EXEMPLO DE COMO FAZER (CORRETO):
"Boa, Welton! Governan√ßa de dados parece nome dif√≠cil, mas √© s√≥ 'organizar a casa' para n√£o perder informa√ß√µes importantes. üßπ
O Passo 1 √© saber o que voc√™ tem hoje.
Pega um papel e anota: Quais dados voc√™ guarda dos seus clientes? (Nome, Zap, Endere√ßo?)
Me conta aqui que a gente monta o resto juntos! üëá"
"""


app = FastAPI()

# --- BANCO DE DADOS (SQLite) ---
def iniciar_banco():
    conn = sqlite3.connect('junior_memoria.db')
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS conversas (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT, role TEXT, content TEXT,
            data_hora DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()

def salvar_mensagem(user_id, role, content):
    conn = sqlite3.connect('junior_memoria.db')
    cursor = conn.cursor()
    cursor.execute('INSERT INTO conversas (user_id, role, content) VALUES (?, ?, ?)', (user_id, role, content))
    conn.commit()
    conn.close()

def recuperar_historico(user_id, limite=10):
    conn = sqlite3.connect('junior_memoria.db')
    cursor = conn.cursor()
    cursor.execute('SELECT role, content FROM conversas WHERE user_id = ? ORDER BY id DESC LIMIT ?', (user_id, limite))
    mensagens = cursor.fetchall()
    conn.close()
    
    # Formata para a Groq (user/system/assistant)
    historico = []
    for m in mensagens[::-1]:
        # Converte nomes de roles se necess√°rio
        role = m[0]
        if role == "model": role = "assistant" 
        historico.append({"role": role, "content": m[1]})
    return historico

# Inicia o banco
iniciar_banco()

class ZapMessage(BaseModel):
    user_id: str
    message: Optional[str] = None
    text: Optional[str] = None
    audio_base64: Optional[str] = None

# --- ROTA PRINCIPAL ---
@app.post("/chat")
async def chat_endpoint(dados: ZapMessage):
    user_id = dados.user_id
    texto_usuario = dados.message or dados.text or ""
    
    print(f"\nüì© Mensagem recebida de {user_id}")

    # 1. TRANSCRI√á√ÉO DE √ÅUDIO (Groq Whisper)
    if dados.audio_base64:
        print("üé§ √Åudio detectado! Transcrevendo...")
        try:
            # Limpa o base64
            b64_clean = dados.audio_base64
            if "," in b64_clean:
                b64_clean = b64_clean.split(",")[1]
            
            # Salva tempor√°rio
            arquivo_temp = f"temp_{user_id}.ogg"
            with open(arquivo_temp, "wb") as f:
                f.write(base64.b64decode(b64_clean))
            
            # Transcreve
            with open(arquivo_temp, "rb") as arquivo_audio:
                transcricao = client.audio.transcriptions.create(
                    file=("audio.ogg", arquivo_audio),
                    model="whisper-large-v3",
                    language="pt"
                )
            texto_usuario = transcricao.text
            print(f"üìù Transcri√ß√£o: {texto_usuario}")
            
            if os.path.exists(arquivo_temp):
                os.remove(arquivo_temp)
            
        except Exception as e:
            print(f"‚ùå Erro transcri√ß√£o: {e}")
            return {"response_text": "N√£o consegui ouvir o √°udio. Pode escrever?", "audio_response": None}

    if not texto_usuario:
        return {"response_text": "...", "audio_response": None}

    # 2. INTELIG√äNCIA (Groq Llama 3.3)
    try:
        # Salva msg do usu√°rio
        salvar_mensagem(user_id, "user", texto_usuario)
        
        # Recupera hist√≥rico
        historico = recuperar_historico(user_id)
        
        # Monta as mensagens (Sistema + Hist√≥rico + Nova Mensagem)
        mensagens_envio = [{"role": "system", "content": SYSTEM_PROMPT}] + historico
        # Se a √∫ltima mensagem do hist√≥rico n√£o for a atual (caso j√° tenha salvo), n√£o adiciona duplicado
        # Mas no nosso fluxo, salvamos antes e recuperamos. O recuperar pega a atual. 
        # Ajuste seguro: adicionar a mensagem atual explicitamente se ela n√£o veio no hist√≥rico
        if not historico or historico[-1]['content'] != texto_usuario:
             mensagens_envio.append({"role": "user", "content": texto_usuario})

    # Chama a Groq
        chat_completion = client.chat.completions.create(
            messages=mensagens_envio,
            # Modelo Versatile (R√°pido e Inteligente)
            model="llama-3.3-70b-versatile",
            
            # 0.5 = Criativo o suficiente para ser simp√°tico, 
            # mas r√≠gido o suficiente para N√ÉO inventar nomes.
            temperature=0.5, 
            
            # 450 = Margem de seguran√ßa. 
            # Ele vai usar s√≥ uns 100 ou 150 na pr√°tica (por causa do prompt "Seja breve"),
            # mas se precisar explicar algo complexo, ele tem espa√ßo e n√£o corta.
            max_tokens=450
        )
        
        resposta_texto = chat_completion.choices[0].message.content
        
        # Salva resposta
        salvar_mensagem(user_id, "assistant", resposta_texto)
        print(f"ü§ñ Resposta Groq: {resposta_texto}")

        return {"response_text": resposta_texto, "audio_response": None}

    except Exception as e:
        print(f"‚ùå Erro Groq: {str(e)}")
        # Se der erro de modelo de novo, fallback para o instant (mais r√°pido)
        return {"response_text": "Tive um lapso de mem√≥ria, pode repetir?", "audio_response": None}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5000)